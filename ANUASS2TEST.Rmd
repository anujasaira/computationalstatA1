---
title: "ANUJATESTASS2"
author: "Anuja Saira Abraham"
date: "2023-06-02"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

## EXERCISE 2- WE NEED SOME MUSIC!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(boot)
library(tidyverse)
library(reshape2)
library(combinat)

```

DESCRIPTION OF THE VARIABLES AND EXPLORATORY ANALYSIS: Considering the data saved in spot.RDS, a description of the variables can be found on Kaggle:

\- Acousticness: a confidence measure from 0.0 to 1.0 of whether the track is acoustic.
1.0 represents high confidence the track is acoustic.

\- Danceability: danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.
A value of 0.0 is least danceable and 1.0 is most danceable.

\- Duration_ms: the track length in milliseconds.

\- Energy:energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity.
Typically, energetic tracks feel fast, loud, and noisy.

\- Explicit: whether or not the track has explicit lyrics (true = yes it does; false = no it does not OR unknown)

\- id: the Spotify ID for the track.

\- Instrumentalness: predicts whether a track contains no vocals.
"Ooh" and "aah" sounds are treated as instrumental in this context.
Rap or spoken word tracks are clearly "vocal".
The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content.

\- Liveness: detects the presence of an audience in the recording.
Higher liveness values represent an increased probability that the track was performed live.
A value above 0.8 provides strong likelihood that the track is live.

\- Loudness: the overall loudness of a track in decibels (dB).

\- Name:name of the track.

\- Popularity: the popularity of a track is a value between 0 and 100, with 100 being the most popular.
The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are.
Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past.
Duplicate tracks (e.g. the same track from a single and an album) are rated independently.
Artist and album popularity is derived mathematically from track popularity.

\- Release_date of the song

\- Speechiness: speechiness detects the presence of spoken words in a track.
The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.Values below 0.33 most likely represent music and other non-speech-like tracks.

\- Tempo:the overall estimated tempo of a track in beats per minute (BPM).
In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.

\- Valence: a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track.
Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).

\- First_auth: first author of the song.

\- n: number of song for each artist.

\- pop: variable containing the original column popularity rescaled between 0 and 1.

```{r}
songs <- readRDS("spot (1).RDS")
head(songs)
```

```{r}
boxplot(popularity~first_auth,data=songs)
```

Focusing on "pop" and given two artists, we want to measure their different in popularity.
Let X and Y denote the vectors of popularity measurements of the songs of two given artists.
We measure their difference with:

$$
T(X, Y) = \left| \text{median}(\text{logit}(X)) - \text{median}(\text{logit}(Y)) \right|
$$ After implementing this estimator to compare the popularity of AC/DC and Kanye West, we provide a a matrix with all pairwise comparisons.

```{r}
u_art<- unique(songs$first_auth)


X <- songs$pop[songs$first_auth == "AC/DC"]

# Extract popularity measurements for Artist Y
Y <- songs$pop[songs$first_auth == "Kanye West"]

med_logit_X <-median( logit(X))
med_logit_Y <-median( logit(Y))

T_XY <- abs(med_logit_X-med_logit_Y)

pop_diff_T <- function(){
  res<-sapply(1:40, function(x) {
    sapply(1:40, function(y) {
      abs(median(logit(songs$pop[songs$first_auth == u_art[x]]))-median(logit(songs$pop[songs$first_auth ==  u_art[y]])))
    })
  })
  return(res)
}

pop_diff<- pop_diff_T()

rownames(pop_diff) <- u_art
colnames(pop_diff) <- u_art

ggplot(melt(pop_diff),aes(Var1,Var2))+
  geom_tile(aes(fill = value), colour = "white")  +
  scale_fill_gradient(low = "white", high = "red")+
  theme(axis.text.x = element_text(angle=90,hjust = 1,siz=5),
        axis.text.y = element_text(hjust = 1,siz=5))

```

Now we perform a hypothesis testing to assess the absence of difference between the popularity of two artists measured via T(X,Y) and perform a sequence of pairwise permutation tests reporting the estimated p-values.

```{r}
data<-songs
p_values <- matrix(0,nrow = length(u_art),ncol = length(u_art))
for (i in 1:length(u_art)){
  for(j in 1:length(u_art)){
   if(i>=j){
    
      X <- data[data$first_auth ==  u_art[i],"pop"]
      Y <- data[data$first_auth ==  u_art[j],"pop"]
      observed_stat=abs(median(logit(songs$pop[songs$first_auth == u_art[i]]))-median(logit(songs$pop[songs$first_auth ==  u_art[j]])))
      
      
      
      num_perm<- 1000
      permutation_stat<- numeric(num_perm)
      for (k in 1:num_perm){
        combined<- union_all(X,Y)
        combined$pop <- sample(combined$pop,nrow(combined),replace = F)
        perm_X<- combined$pop[1:length(X$pop)]
        perm_Y<-combined$pop[(length(X$pop)+1):(length(X$pop)+length(Y$pop))]
        permutation_stat[k]<- abs(median(logit(perm_X))-median(logit(perm_Y)))
        
      }
      
      p_value <- mean(permutation_stat>=observed_stat)
      
      p_values[i,j]<- p_value
      p_values[j,i]<- p_value
      
      
    }
  }
}


p_values

rownames(p_values) <- u_art
colnames(p_values) <- u_art

ggplot(melt(p_values),aes(Var1,Var2))+
  geom_tile(aes(fill = value), colour = "white")  +
  scale_fill_gradient(low = "white", high = "red")+
  theme(axis.text.x = element_text(angle=90,hjust = 1,siz=5),
        axis.text.y = element_text(hjust = 1,siz=5))

```

????????????????????????????????????????????

```{r}
boxplot( data$pop ~ data$first_auth,
         col= cutree( hclust(as.dist(1-p_values)),5))
```

Now, we apply the scale() function to "pop" and perform, for each artist, a single-sample t-test to assess:

$$
H_0: \mu = 0
$$

$$
H_1: \mu > 0
$$

```{r}

pop_scaled <- scale(data$pop)
df<- data.frame(Artist = data$first_auth,pop_scaled)

t_test<- function(df,artist){
  x<- df[df$Artist==artist,"pop_scaled"]
  t_test<- t.test(x,mu=0,alternative = "greater")
  return(t_test$p.value)
}

p_values<- sapply(unique(df$Artist),t_test,df=df)

prob_violation <- sum(p_values<0.10)/length(p_values)
prob_violation #probability of the global null to be violated

plot(sort(p_values), type="l",col = "blue", main = "Density Plot of P-values", xlab = "P-values", ylab = "Density", ylim=c(0,2))
```

The p.adjust function is used to adjust p-values for multiple comparisons.
When conducting multiple statistical tests or comparing multiple groups, the probability of obtaining a significant result by chance increases.
Multiple comparison procedures, such as adjusting p-values, are used to control for this increased risk of false positives (Type I errors).The p.adjust function takes a vector of p-values as input and applies various methods to adjust these p-values: Bonferroni adjustment,Benjamini-Hochberg and Holm.
In summary, the p.adjust function helps in minimizing Type I errors by applying appropriate adjustments to p-values, depending on the chosen method.

```{r}
adjusted_bh <- p.adjust(p_values, method = "BH")
adjusted_bonferroni <- p.adjust(p_values, method = "bonferroni")
adjusted_holm <- p.adjust(p_values, method = "holm")
results <- data.frame(p_values, adjusted_bh, adjusted_bonferroni,adjusted_holm)

# Plotting the p-values and adjusted p-values
plot(sort(p_values), type="l", col = "blue", xlab = "Observation", ylab = "P-value",
     main = "Comparison of P-values and Adjusted P-values")
lines(sort(adjusted_bh), col = "red")
lines(sort(adjusted_bonferroni),  col = "yellow")
lines(sort(adjusted_holm), col = "green")
abline(h = 0.05, lwd = 1, lty = 2)
legend("bottomright", legend = c("P-values", "Adjusted (BH)", "Adjusted (Bonferroni)","Adjusted (Holm)"),
       col = c("blue", "red","yellow","green"), lwd=1,)

```

Holm procedure (will do is soon!!!!!!!!!!!!!!!!!!!!!!!)
